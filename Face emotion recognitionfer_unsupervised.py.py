# -*- coding: utf-8 -*-
"""fer-unsup

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16E8_YUYHAKj3V5USVrGTW0KT4yVMlgXp

# ***Importing Libraries for Data and Image Analysis***
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score # Used to measure how well the clusters are separated.
from sklearn.model_selection import train_test_split
import umap # Used for reducing dimensions while keeping the data's structure intact.
import cv2
import dlib
import joblib
from google.colab import files

"""# ***Loading and Preprocessing Facial Expression Data***"""

def load_and_preprocess_data(file_path="fer2013.csv", test_size=0.2, random_state=42):
    try:
        # Loading the dataset
        df = pd.read_csv(file_path)

        # Converting pixel strings to arrays
        images = []
        for i in range(len(df)):
            pixels = [float(x) for x in df.iloc[i]['pixels'].split()]
            images.append(pixels)

        X = np.array(images)

        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        # Split data for traing and testing
        X_train, X_test = train_test_split(
            X_scaled,
            test_size=test_size,
            random_state=random_state
        )

        # Get row numbers for train and test sets
        train_indices, test_indices = train_test_split(
            df.index,
            test_size=test_size,
            random_state=random_state
        )

        return X_train, X_test, df, train_indices, test_indices, scaler
    except FileNotFoundError:
        print(f"Error: Could not find file at {file_path}")
        return None, None, None, None, None, None
    except Exception as e:
        print(f"Error in data preprocessing: {str(e)}")
        return None, None, None, None, None, None

X_train, X_test, df, train_indices, test_indices, scaler = load_and_preprocess_data()

"""# ***Creating UMAP model***"""

# Note: I didn't use a CNN in the unsupervised model because CNNs need labels for training and are designed for classification.
# UMAP is better here as it reduces dimensions while keeping the data's structure, making it better for finding natural groupings.
def perform_umap_reduction(X_train, X_test, n_components=2, random_state=42):
    try:
      # Creating a umap model
        umap_model = umap.UMAP(n_components=n_components, random_state=random_state)
        X_umap_train = umap_model.fit_transform(X_train)
        X_umap_test = umap_model.transform(X_test)
        return X_umap_train, X_umap_test, umap_model
    except Exception as e:
        print(f"Error in UMAP reduction: {str(e)}")
        return None, None, None
X_umap_train, X_umap_test, umap_model = perform_umap_reduction(X_train, X_test)

"""# ***K-means cluster***"""

def perform_kmeans_clustering(X_umap_train, X_umap_test, n_clusters=7, random_state=42):
    try:
      # Creating a K-Means model
        kmeans = KMeans(n_clusters=n_clusters, random_state=random_state)
        cluster_labels_train = kmeans.fit_predict(X_umap_train)
        cluster_labels_test = kmeans.predict(X_umap_test)
        return cluster_labels_train, cluster_labels_test, kmeans
    except Exception as e:
        print(f"Error in K-means clustering: {str(e)}")
        return None, None, None
cluster_labels_train, cluster_labels_test, kmeans = perform_kmeans_clustering(X_umap_train, X_umap_test)

def plot_combined_clusters(X_umap_train, cluster_labels_train, X_umap_test, cluster_labels_test):
    try:
        plt.figure(figsize=(12, 8))

        # Plotting training data with circles
        plt.scatter(
            X_umap_train[:, 0],
            X_umap_train[:, 1],
            c=cluster_labels_train,
            cmap='rainbow',
            marker='o',
            alpha=0.7,
            label='Training Data'
        )

        # Plotting test data with triangles
        plt.scatter(
            X_umap_test[:, 0],
            X_umap_test[:, 1],
            c=cluster_labels_test,
            cmap='rainbow',
            marker='^',
            alpha=0.7,
            label='Test Data'
        )

       # Adding labels
        plt.title("K-Means Cluster Plot Using UMAP (Training and Test Data)")
        plt.xlabel("UMAP Component 1")
        plt.ylabel("UMAP Component 2")
        plt.legend()
        plt.colorbar(label='Cluster')
        plt.show()
    except Exception as e:
        print(f"Error in plotting: {str(e)}")

# Display the cluster plot
plot_combined_clusters(X_umap_train, cluster_labels_train, X_umap_test, cluster_labels_test)

"""# ***Saving model***"""

components = {
    "scaler": scaler,
    "umap_model": umap_model,
    "kmeans": kmeans
}
joblib.dump(components, "fer_unsupervised_model.pkl")
print("Unsupervised model components saved as fer_unsupervised_model.pkl")

"""# ***Loading model***"""

kmeans = joblib.load("fer_unsupervised_model.pkl")
print("K-Means model loaded successfully!")

"""# ***Evaluating Cluster Quality with Silhouette Scores***"""

# Chosen to evaluate clustering quality because it clearly measures how well-separated the clusters are, making it simple and effective for comparing different clustering configurations.
def evaluate_clustering(X_umap_train, cluster_labels_train, X_umap_test, cluster_labels_test):
    try:
        # Calculate silhouette score for training data
        silhouette_train = silhouette_score(X_umap_train, cluster_labels_train)
        # Calculate silhouette score for testing data
        silhouette_test = silhouette_score(X_umap_test, cluster_labels_test)
        print(f"Silhouette Score - Training Data: {silhouette_train:.4f}")
        print(f"Silhouette Score - Test Data: {silhouette_test:.4f}")
        return silhouette_train, silhouette_test
    except Exception as e:
        print(f"Error in clustering evaluation: {str(e)}")
        return None, None
silhouette_train, silhouette_test = evaluate_clustering(X_umap_train, cluster_labels_train, X_umap_test, cluster_labels_test)

"""# ***Displaying Facial Emotion Images from FER-2013 Dataset***"""

# Load unsupervised components
comp = joblib.load("fer_unsupervised_model.pkl")
scaler = comp["scaler"]
umap_model = comp["umap_model"]
kmeans = comp["kmeans"]

df = pd.read_csv("fer2013.csv")
X = []
for i in range(len(df)):
    pixels = [float(x) for x in df.iloc[i]['pixels'].split()]
    X.append(pixels)
X = np.array(X, dtype=np.float32)

# Predict clusters
X_scaled = scaler.transform(X)
X_umap = umap_model.transform(X_scaled)
clusters = kmeans.predict(X_umap)

# Group up to 8 images per cluster
max_examples = 8
cl_dict = {}
for i, cl in enumerate(clusters):
    if cl not in cl_dict:
        cl_dict[cl] = []
    if len(cl_dict[cl]) < max_examples:
        px = [int(float(p)) for p in df.iloc[i]['pixels'].split()]
        img_2d = np.array(px, dtype=np.uint8).reshape(48, 48)
        cl_dict[cl].append(img_2d)

def plot_clusters_label_above(cluster_dict):
    nrows = len(cluster_dict)
    ncols = max_examples
    plt.figure(figsize=(ncols*1.8, nrows*2.5))

    row = 0
    for cl, imgs in sorted(cluster_dict.items()):
        # Plot the images in this cluster
        for col, img in enumerate(imgs):
            ax = plt.subplot(nrows, ncols, row*ncols + col + 1)
            ax.imshow(img, cmap='gray')
            ax.axis('off')
        plt.figtext(0.5, (nrows - row - 0.1)/nrows,
                    f"Predicted: {cl}", ha='center', fontsize=12)
        row += 1

    plt.tight_layout()
    plt.show()

plot_clusters_label_above(cl_dict)

"""# ***Testing the model***"""

def cluster_my_image():
    # Asking the user to choose a file
    print("Choose a file to upload:")
    uploaded = files.upload()
    image_path = next(iter(uploaded.keys()))
    print("File chosen:", image_path)

    # Loading the unsupervised model
    components = joblib.load("fer_unsupervised_model.pkl")
    scaler = components["scaler"]
    umap_model = components["umap_model"]
    kmeans = components["kmeans"]
    print("Unsupervised model loaded.")

    # Reading the image
    img = cv2.imread(image_path)
    if img is None:
        print("Failed to load the chosen file.")
        return

    # Convert to grayscale and detect face with Haar Cascade
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30,30))

    if len(faces) == 0:
        print("No face detected, showing original image.")
        show_image(img, "No Face Found")
        return

    # Processing the detected face
    x, y, w, h = faces[0]
    face_roi = gray[y:y+h, x:x+w]

    # Resize to 48x48
    face_resized = cv2.resize(face_roi, (48, 48))
    face_flat = face_resized.flatten().reshape(1, -1).astype("float32")

    # Scale, transform, and predict cluster
    face_scaled = scaler.transform(face_flat)
    face_umap = umap_model.transform(face_scaled)
    cluster_label = kmeans.predict(face_umap)[0]

    # Draw bounding box and label
    cv2.rectangle(img, (x, y), (x+w, y+h), (0,255,0), 2)
    cv2.putText(img, f"Cluster {cluster_label}", (x, y-10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)
    show_image(img, f"Predicted Cluster: {cluster_label}")

def show_image(bgr_image, title):
    """ Helper to display a BGR image with Matplotlib. """
    rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)
    plt.figure(figsize=(6, 6))
    plt.imshow(rgb_image)
    plt.title(title)
    plt.axis("off")
    plt.show()

# Run the function
cluster_my_image()

def cluster_my_image():
    # Asking the user to choose a file
    print("Choose a file to upload:")
    uploaded = files.upload()
    image_path = next(iter(uploaded.keys()))
    print("File chosen:", image_path)

    # Loading the unsupervised model
    components = joblib.load("fer_unsupervised_model.pkl")
    scaler = components["scaler"]
    umap_model = components["umap_model"]
    kmeans = components["kmeans"]
    print("Unsupervised model loaded.")

    # Reading the image
    img = cv2.imread(image_path)
    if img is None:
        print("Failed to load the chosen file.")
        return

    # Convert to grayscale and detect face with Haar Cascade
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30,30))

    if len(faces) == 0:
        print("No face detected, showing original image.")
        show_image(img, "No Face Found")
        return

    # Processing the detected face
    x, y, w, h = faces[0]
    face_roi = gray[y:y+h, x:x+w]

    # Resize to 48x48
    face_resized = cv2.resize(face_roi, (48, 48))
    face_flat = face_resized.flatten().reshape(1, -1).astype("float32")

    # Scale, transform, and predict cluster
    face_scaled = scaler.transform(face_flat)
    face_umap = umap_model.transform(face_scaled)
    cluster_label = kmeans.predict(face_umap)[0]

    # 8) Draw bounding box and label
    cv2.rectangle(img, (x, y), (x+w, y+h), (0,255,0), 2)
    cv2.putText(img, f"Cluster {cluster_label}", (x, y-10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)
    show_image(img, f"Predicted Cluster: {cluster_label}")

def show_image(bgr_image, title):
    """ Helper to display a BGR image with Matplotlib. """
    rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)
    plt.figure(figsize=(6, 6))
    plt.imshow(rgb_image)
    plt.title(title)
    plt.axis("off")
    plt.show()

# Run the function
cluster_my_image()

def cluster_my_image():
    # Asking the user to choose a file
    print("Choose a file to upload:")
    uploaded = files.upload()
    image_path = next(iter(uploaded.keys()))
    print("File chosen:", image_path)

    # Loading the unsupervised model
    components = joblib.load("fer_unsupervised_model.pkl")
    scaler = components["scaler"]
    umap_model = components["umap_model"]
    kmeans = components["kmeans"]
    print("Unsupervised model loaded.")

    # Reading the image
    img = cv2.imread(image_path)
    if img is None:
        print("Failed to load the chosen file.")
        return

    # Convert to grayscale and detect face with Haar Cascade
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30,30))

    if len(faces) == 0:
        print("No face detected, showing original image.")
        show_image(img, "No Face Found")
        return

    # Processing the detected face
    x, y, w, h = faces[0]
    face_roi = gray[y:y+h, x:x+w]

    # Resize to 48x48
    face_resized = cv2.resize(face_roi, (48, 48))
    face_flat = face_resized.flatten().reshape(1, -1).astype("float32")

    # 7) Scale, transform, and predict cluster
    face_scaled = scaler.transform(face_flat)
    face_umap = umap_model.transform(face_scaled)
    cluster_label = kmeans.predict(face_umap)[0]

    # 8) Draw bounding box and label
    cv2.rectangle(img, (x, y), (x+w, y+h), (0,255,0), 2)
    cv2.putText(img, f"Cluster {cluster_label}", (x, y-10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)
    show_image(img, f"Predicted Cluster: {cluster_label}")

def show_image(bgr_image, title):
    """ Helper to display a BGR image with Matplotlib. """
    rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)
    plt.figure(figsize=(6, 6))
    plt.imshow(rgb_image)
    plt.title(title)
    plt.axis("off")
    plt.show()

# Run the function
cluster_my_image()

def cluster_my_image():
    # Asking the user to choose a file
    print("Choose a file to upload:")
    uploaded = files.upload()
    image_path = next(iter(uploaded.keys()))
    print("File chosen:", image_path)

    # Loading the unsupervised model
    components = joblib.load("fer_unsupervised_model.pkl")
    scaler = components["scaler"]
    umap_model = components["umap_model"]
    kmeans = components["kmeans"]
    print("Unsupervised model loaded.")

    # Reading the image
    img = cv2.imread(image_path)
    if img is None:
        print("Failed to load the chosen file.")
        return

    # Convert to grayscale and detect face with Haar Cascade
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30,30))

    if len(faces) == 0:
        print("No face detected, showing original image.")
        show_image(img, "No Face Found")
        return

    # Processing the detected face
    x, y, w, h = faces[0]
    face_roi = gray[y:y+h, x:x+w]

    # Resize to 48x48
    face_resized = cv2.resize(face_roi, (48, 48))
    face_flat = face_resized.flatten().reshape(1, -1).astype("float32")

    # Scale, transform, and predict cluster
    face_scaled = scaler.transform(face_flat)
    face_umap = umap_model.transform(face_scaled)
    cluster_label = kmeans.predict(face_umap)[0]

    # Draw bounding box and label
    cv2.rectangle(img, (x, y), (x+w, y+h), (0,255,0), 2)
    cv2.putText(img, f"Cluster {cluster_label}", (x, y-10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)
    show_image(img, f"Predicted Cluster: {cluster_label}")

def show_image(bgr_image, title):
    """ Helper to display a BGR image with Matplotlib. """
    rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)
    plt.figure(figsize=(6, 6))
    plt.imshow(rgb_image)
    plt.title(title)
    plt.axis("off")
    plt.show()

# Run the function
cluster_my_image()

def cluster_my_image():
    # Asking the user to choose a file
    print("Choose a file to upload:")
    uploaded = files.upload()
    image_path = next(iter(uploaded.keys()))
    print("File chosen:", image_path)

    # Loading the unsupervised model
    components = joblib.load("fer_unsupervised_model.pkl")
    scaler = components["scaler"]
    umap_model = components["umap_model"]
    kmeans = components["kmeans"]
    print("Unsupervised model loaded.")

    # Reading the image
    img = cv2.imread(image_path)
    if img is None:
        print("Failed to load the chosen file.")
        return

    # Convert to grayscale and detect face with Haar Cascade
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30,30))

    if len(faces) == 0:
        print("No face detected, showing original image.")
        show_image(img, "No Face Found")
        return

    # Processing the detected face
    x, y, w, h = faces[0]
    face_roi = gray[y:y+h, x:x+w]

    # Resize to 48x48
    face_resized = cv2.resize(face_roi, (48, 48))
    face_flat = face_resized.flatten().reshape(1, -1).astype("float32")

    # Scale, transform, and predict cluster
    face_scaled = scaler.transform(face_flat)
    face_umap = umap_model.transform(face_scaled)
    cluster_label = kmeans.predict(face_umap)[0]

    # Draw bounding box and label
    cv2.rectangle(img, (x, y), (x+w, y+h), (0,255,0), 2)
    cv2.putText(img, f"Cluster {cluster_label}", (x, y-10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)
    show_image(img, f"Predicted Cluster: {cluster_label}")

def show_image(bgr_image, title):
    """ Helper to display a BGR image with Matplotlib. """
    rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)
    plt.figure(figsize=(6, 6))
    plt.imshow(rgb_image)
    plt.title(title)
    plt.axis("off")
    plt.show()

# Run the function
cluster_my_image()

"""# ***Testing my model using webcam captured images***"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import joblib, cv2, numpy as np, matplotlib.pyplot as plt
from google.colab import output
import base64

def take_photo(filename='photo.jpg', quality=0.8):
    js = f"""
    async function takePhoto(quality) {{
      const div = document.createElement('div');
      const btn = document.createElement('button');
      btn.textContent = 'Capture';
      div.appendChild(btn);
      document.body.appendChild(div);

      const video = document.createElement('video');
      video.style.display = 'block';
      document.body.appendChild(video);

      const stream = await navigator.mediaDevices.getUserMedia({{video: true}});
      video.srcObject = stream;
      await new Promise((r) => video.onloadedmetadata = r);
      video.play();

      await new Promise((r) => btn.onclick = r);

      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext('2d').drawImage(video, 0, 0);

      stream.getTracks().forEach(track => track.stop());
      video.remove();
      div.remove();

      return canvas.toDataURL('image/jpeg', quality);
    }}
    takePhoto({quality});
    """
    data = output.eval_js(js)
    img = cv2.imdecode(np.frombuffer(base64.b64decode(data.split(',')[1]), np.uint8), cv2.IMREAD_COLOR)
    cv2.imwrite(filename, img)
    return filename

def show_image(bgr_img, title):
    rgb = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB)
    plt.figure(figsize=(6,6))
    plt.imshow(rgb)
    plt.title(title)
    plt.axis('off')
    plt.show()

def capture_and_predict_cluster():
    path = take_photo()
    comp = joblib.load("fer_unsupervised_model.pkl")
    scaler, umap_model, kmeans = comp["scaler"], comp["umap_model"], comp["kmeans"]

    img = cv2.imread(path)
    if img is None:
        print("Failed to load image.")
        return
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
    faces = face_cascade.detectMultiScale(gray, 1.1, 5)

    if len(faces) == 0:
        show_image(img, "No Face Detected")
        return

    x, y, w, h = faces[0]
    face = gray[y:y+h, x:x+w]
    face_resized = cv2.resize(face, (48, 48)).astype('float32').reshape(1, -1)

    face_scaled = scaler.transform(face_resized)
    face_umap = umap_model.transform(face_scaled)
    cluster = kmeans.predict(face_umap)[0]

    cv2.rectangle(img, (x, y), (x+w, y+h), (0,255,0), 2)
    cv2.putText(img, f"Cluster {cluster}", (x, y-10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)
    show_image(img, f"Cluster {cluster}")

capture_and_predict_cluster()